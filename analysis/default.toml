#=====================================#
#       GENERAL CONFIGURATION        #
#=====================================#
# Base directory where all workflow data is stored. only used to build paths 
# for input and output graph data (and not for plots or statistics)
workflow_data = "/beegfs/home/msantima/OpenAlexCollaborations/"
# Country code for the analized country
country = "IT"
# Country to be analyzed. Only records associated with this country will be considered.
analized_country_full = "Italy"
# Base directory where all statistics will be stored
statistics_out_basedir = "/beegfs/home/msantima/openalex-collaboration-crawler/analysis/statistics-it"

# List of year intervals for aggregating data. Each interval is a pair tuple of (start, end).
# If None, yearly intervals are used. Only affects CCDF computations.
time_intervals = [
    [1970, 1989],
    [1990, 1999],
    [2000, 2009],
    [2010, 2011],
    [2012, 2014],
    [2015, 2024]
]

#=====================================#
#       METADATA ANALISYS STEP        #
#=====================================#
[metadata_analisys.inputs]

# Path to the metadata CSV file produced during the graph-generation stage.
# This file contains all publication- or work-level metadata used in the analysis.
metadata_path = "metadata_dataset.csv"

# Datasets from which to compute CCDFs will be read. leave empty if graphs are on the root folder
graph_directory = ""

[metadata_analisys.outputs]
# Output filename for the plot showing the number of works per year.
works_per_year_plot_filename = "works_per_year.pdf"

# Output filename for the CSV dataset containing yearly work counts.
works_per_year_dataset = "works_per_year.csv"

# Output filename for the plot tracking application-domain trends over time.
application_domain_plot_filename = "application_domains_over_time.pdf"

# Output filename for the plot tracking Computer Science topic trends over time.
cs_topics_over_time_plot_filename = "cs_topics_over_time.pdf"

# Directory where CCDF (Complementary Cumulative Distribution Function) plots or data will be stored.
ccdf_path = "ccdf"

# Filename for the metadata plots
ccdf_graph_output_filename = 'ccdfs_year_by_year.pdf'

[metadata_analisys.config]
# Time window for the analysis. Only works published within [start_year, end_year) are used.
start_year = 1970  # inclusive
end_year = 2025  # exclusive
# Maximum number of topics to consider when aggregating or visualizing topic distributions.
max_topics = 8


#=====================================#
#      STRUCTURAL STATISTICS STEP     #
#=====================================#
[structural_statistics.outputs]
# Output file for structural statistics
output_stats_file = "structural_stats.csv"

# Output file for structural statistics of the largest connected component
output_stats_file_largest_cc = "largestCC_structural_stats.csv"


#=====================================#
#           BACKBONES STEP            #
#=====================================#
[backbones]

# Weighted networks directory
inputs.graph_directory = "nets_weighted/"

# Directory where to store the computed backbones
outputs.backbone_directory  = "backbones/"


#=====================================#
# BACKBONE STRUCTURAL STATISTICS STEP #
#=====================================#
[bacbone_structural_statistics.outputs]
# Output file for structural statistics
output_stats_file = "structural_stats_backbone.csv"

# Output file for structural statistics of the largest connected component
output_stats_file_largest_cc = "largestCC_structural_backbone.csv"

#=====================================#
#      COMMUNITY EXTRACTION STEP      #
#=====================================#
[community_extraction.outputs]
# Output folder where computed communities will be stored in pickle format
communities_folder = "communities"

# Output file for the community statistics
statistics_output_file = "communities_statistics.csv"

#=====================================#
#       COMMUNITY STABILITY STEP      #
#=====================================#
[community_stability]

# number of runs for stability evaluation
RUNS = 10

[community_stability.outputs]
# Communities output folder. This will be pickles containig all the communities computed during the proces
communities_output_folder = "stability"

# Output file for the community statistics
statistics_output_file = "communities_stability_statistics.csv"


#=====================================#
#         COMMUNITY FLOW STEP         #
#=====================================#

[community_flow]
# Whether to display the sink community in the flow analysis heatmaps or not
display_sink_community = true
# Community quantiles to compute
quantiles = [25, 50, 60, 70, 80, 90, 95, 99]
# Flow percentile to consider for the flow analysis. only communities with size in the specified percentile will be displayed in the heatmaps
flow_percentile = 99
# Path to output the community size statistics CSV file
outputs.size_statistics_path = "community_quantile_size_distribution.csv"


#=====================================#
#         PLOT GENERATION STEP        #
#=====================================#

[plot_generation.outputs]
structural_step_plot_filename = "structural_stats.pdf"
backbone_structural_step_plot_filename = "backbone_structural_stats.pdf"
random_validation_output_filename = "random_plots_validation_null_hypotesis.pdf"

#=====================================#
#     Graph property validation       #
#=====================================#

[graph_property_validation]
iterations = 10
outputs.stats_out = "graph_property_validation.csv" #Statistics for the original bacbone
outputs.stats_out_random = "graph_property_validation_random.csv" #statistics for the random generated graphs