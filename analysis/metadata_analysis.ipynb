{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2bb7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bac1a1",
   "metadata": {},
   "source": [
    "### Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088c65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Configuration and Input Paths\n",
    "# -----------------------------\n",
    "\n",
    "metadata_path = \"metadata_dataset.csv\"  \n",
    "# Path to the metadata CSV file produced during the graph-generation stage.\n",
    "# This file contains all publication- or work-level metadata used in the analysis.\n",
    "\n",
    "analized_country = \"Italy\"\n",
    "# Country to be analyzed. Only records associated with this country will be considered.\n",
    "\n",
    "start_year = 1990  # inclusive\n",
    "end_year = 2024    # exclusive\n",
    "# Time window for the analysis. Only works published within [start_year, end_year) are used.\n",
    "\n",
    "max_topics = 13\n",
    "# Maximum number of topics to consider when aggregating or visualizing topic distributions.\n",
    "\n",
    "plots_dpi = 700\n",
    "# Resolution (DPI) for all generated PDF figures.\n",
    "\n",
    "# ---------------------------------------\n",
    "# Output Filenames for Datasets and Plots\n",
    "# ---------------------------------------\n",
    "\n",
    "works_per_year_plot_filename = \"works_per_year.pdf\"\n",
    "# Output filename for the plot showing the number of works per year.\n",
    "\n",
    "works_per_year_dataset = \"works_per_year.csv\"\n",
    "# Output filename for the CSV dataset containing yearly work counts.\n",
    "\n",
    "application_domain_plot_filename = \"application_domains_over_time.pdf\"\n",
    "# Output filename for the plot tracking application-domain trends over time.\n",
    "\n",
    "cs_topics_over_time_plot_filename = \"cs_topics_over_time.pdf\"\n",
    "# Output filename for the plot tracking Computer Science topic trends over time.\n",
    "\n",
    "ccdf_path = \"./ccdfs\"\n",
    "# Directory where CCDF (Complementary Cumulative Distribution Function) plots or data\n",
    "# will be stored. This feature is still a work in progress.\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# External Mappings (Required for Topic Normalization)\n",
    "# ----------------------------------------------------\n",
    "# These mappings must be provided manually if analyzing fields outside Computer Science.\n",
    "\n",
    "from topic_to_category import topic_to_category\n",
    "# Dictionary mapping fine-grained CS topics to broader topic categories.\n",
    "\n",
    "from mappings import topics_mapping, application_domains_mapping\n",
    "# topics_mapping: Normalizes topic names and groups synonyms/variants.\n",
    "# application_domains_mapping: Mapping to unify and filter application-domain labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352715c6",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e7dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "with open(metadata_path, 'r') as f:\n",
    "    next(f) #skip header\n",
    "    \n",
    "    for line in f:\n",
    "        parts = line.strip().split(',')\n",
    "        work_id = parts[0]\n",
    "        year = parts[1]\n",
    "        number_of_authors = parts[2]\n",
    "\n",
    "        if year not in data:\n",
    "            data[year] = []\n",
    "\n",
    "        data[year].append({\"id\" : parts[0], \"author_count\" : parts[2], \"topics\" : parts[3].split(';')})\n",
    "\n",
    "data_sorted = dict(sorted(data.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba20e6",
   "metadata": {},
   "source": [
    "### Papers by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [int(year) for year in data_sorted.keys() if year.isdigit() and int(year) >= start_year and int(year) < end_year]\n",
    "y = [len(data_sorted[year]) for year in data_sorted.keys() if year.isdigit() and int(year) >= start_year  and int(year) < end_year]\n",
    "\n",
    "print(f\"Computed {len(y)} time intervals\")\n",
    "\n",
    "fig = plt.figure(figsize=(13, 4))\n",
    "\n",
    "plt.plot(x, y, marker='o')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Works')\n",
    "plt.grid(True)\n",
    "plt.xticks(x, rotation=60)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.title(f\"Number of published works over year: {analized_country}\", fontweight='bold', fontsize=15)\n",
    "plt.savefig(works_per_year_plot_filename, bbox_inches='tight', dpi=plots_dpi)\n",
    "\n",
    "index = list(range(len(x)))\n",
    "df = pd.DataFrame({'Year': x, 'Papers': y}, index=index)\n",
    "df.to_csv(works_per_year_plot_filename, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b2208f",
   "metadata": {},
   "source": [
    "### Topic distribution by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_by_year(data, year):\n",
    "    topics = [\n",
    "        t\n",
    "        for work in data[year]\n",
    "        for t in work['topics']\n",
    "    ]\n",
    "    topic_counts = Counter(topics)\n",
    "\n",
    "    # remove 'Computer science'\n",
    "    if 'Computer science' in topic_counts:\n",
    "        del topic_counts['Computer science']\n",
    "\n",
    "    return topic_counts\n",
    "\n",
    "def normalize_topic_counts(topic_counts):\n",
    "    total = sum(topic_counts.values())\n",
    "    normalized_counts = {topic: round((count / total) * 100, 2) for topic, count in topic_counts.items()}\n",
    "    return normalized_counts\n",
    "\n",
    "def get_application_domains(topics_by_year):\n",
    "    # sort topics by frequency\n",
    "    sorted_topics = sorted(topics_by_year.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    return (sorted_topics[:20])\n",
    "\n",
    "def filter(topics, criteria):\n",
    "    to_return = topics.copy()\n",
    "    for topic in criteria.keys():\n",
    "        if topic in to_return:\n",
    "            del to_return[topic]\n",
    "    return to_return\n",
    "\n",
    "def marco_filter(topics, criteria):\n",
    "    to_return = {}\n",
    "\n",
    "    for topic in topics.keys():\n",
    "        if topic not in criteria:\n",
    "            #print(f\"Topic '{topic}' not found in criteria mapping. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        if criteria[topic] == \"Others\":\n",
    "            continue\n",
    "        to_return[topic] = topics[topic]\n",
    "\n",
    "    return to_return\n",
    "\n",
    "\n",
    "def uniform_application_domain(topics, application_domains):\n",
    "    to_return = {}\n",
    "\n",
    "    for topic, freq in topics.items():\n",
    "        new_key = application_domains[topic] if topic in application_domains else topic\n",
    "        to_return[new_key] = to_return.get(new_key, 0) + freq\n",
    "\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bbfd3f",
   "metadata": {},
   "source": [
    "### Application domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead88a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_over_time = {}\n",
    "\n",
    "years = list(range(start_year, end_year))\n",
    "\n",
    "for idx, year in enumerate(years):\n",
    "    \n",
    "    # here we get all topics by year\n",
    "    topics = get_topics_by_year(data_sorted, str(year))\n",
    "    # then we filter out CS topics \n",
    "    # to focus on the application domains\n",
    "    filtered_topics = filter(topics, topics_mapping)\n",
    "    # we need to uniform the application domains\n",
    "    # otherwise we will have specific subtopics (e.g., Medicine, Internal medicine, etc.)\n",
    "    uniformed_topics = uniform_application_domain(filtered_topics, application_domains_mapping)\n",
    "    # then we normalize the counts to get percentages\n",
    "    normalized_topics = normalize_topic_counts(uniformed_topics)\n",
    "    # we sort the topics by percentage\n",
    "    # and we get only the most frequent ones\n",
    "    sorted_topics = dict(sorted(normalized_topics.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    for topic, percentage in list(sorted_topics.items())[:max_topics]:\n",
    "        if topic not in categories_over_time:\n",
    "            categories_over_time[topic] = np.zeros(len(years), dtype=float)\n",
    "        \n",
    "        categories_over_time[topic][idx] = percentage\n",
    "        \n",
    "\n",
    "years = list(range(start_year, end_year))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "bottom = np.zeros(len(years))\n",
    "\n",
    "width = 0.75\n",
    "\n",
    "cmap = plt.get_cmap(\"tab20\")\n",
    "colors = cmap.colors\n",
    "\n",
    "hatches = ['/', '\\\\', '|', '-', '+', 'x', 'o', '\\\\|', '.', '*']\n",
    "\n",
    "for i, (category, percentage) in enumerate(categories_over_time.items()):\n",
    "    plt.bar(years, percentage, width, bottom=bottom, label=category, color=colors[i], edgecolor='white', linewidth=2) #, hatch=hatches[i % len(hatches)]\n",
    "    bottom += np.array(percentage)\n",
    "\n",
    "plt.xlim(start_year-1, end_year)\n",
    "\n",
    "# ylabel\n",
    "plt.ylabel('Percentage of Works (%)', fontweight='bold', fontsize=13)\n",
    "plt.title(f\"Application Domains Over Time: {analized_country}\", fontweight='bold', fontsize=15)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3,1))\n",
    "plt.savefig(application_domain_plot_filename, bbox_inches='tight', dpi=plots_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebefe6da",
   "metadata": {},
   "source": [
    "### CS subfields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_topics_over_time = {}\n",
    "\n",
    "topics = get_topics_by_year(data_sorted, str(1990))\n",
    "filtered_topics = filter(topics, application_domains_mapping)\n",
    "marco_filtered_topics = marco_filter(filtered_topics, topic_to_category)\n",
    "\n",
    "years = list(range(start_year, end_year))\n",
    "\n",
    "for idx, year in enumerate(years):\n",
    "    # here we get all topics by year\n",
    "    topics = get_topics_by_year(data_sorted, str(year))\n",
    "    # then we filter out app domains topics \n",
    "    # to focus on CS-related subfields\n",
    "    filtered_topics = filter(topics, application_domains_mapping)\n",
    "    marco_filtered_topics = marco_filter(filtered_topics, topic_to_category)\n",
    "    # we need to uniform the subtopics\n",
    "    uniformed_topics = uniform_application_domain(marco_filtered_topics, topic_to_category)#cs_topics\n",
    "    # then we normalize the counts to get percentages\n",
    "    normalized_topics = normalize_topic_counts(uniformed_topics)\n",
    "    # we sort the topics by percentage\n",
    "    # and we get only the most frequent ones\n",
    "    sorted_topics = dict(sorted(normalized_topics.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    for topic, percentage in list(sorted_topics.items())[:max_topics]:\n",
    "        if topic not in cs_topics_over_time:\n",
    "            cs_topics_over_time[topic] = np.zeros(len(years), dtype=float)\n",
    "\n",
    "        cs_topics_over_time[topic][idx] = percentage\n",
    "\n",
    "# transform cs_topic_over_time to df\n",
    "cs_df = pd.DataFrame(cs_topics_over_time, index=years)\n",
    "\n",
    "# sum the values over the rows\n",
    "cs_df['Total'] = cs_df.sum(axis=1)\n",
    "\n",
    "# create a new column 'Other' that is 100 - Total\n",
    "cs_df['Other'] = 100 - cs_df['Total']\n",
    "\n",
    "\n",
    "cs_topics_over_time['Other'] = cs_df['Other'].values\n",
    "\n",
    "years = list(range(start_year, end_year))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "bottom = np.zeros(len(years))\n",
    "\n",
    "width = 0.75\n",
    "\n",
    "cmap = plt.get_cmap(\"tab20\")\n",
    "colors = cmap.colors\n",
    "\n",
    "hatches = ['/', '\\\\', '|', '-', '+', 'x', 'o', '\\\\|', '.', '*']\n",
    "\n",
    "for i, (topic, percentage) in enumerate(cs_topics_over_time.items()):\n",
    "    if topic == \"Other\":\n",
    "        plt.bar(years, percentage, width, bottom=bottom, label=topic, color='lightgrey', edgecolor='white', linewidth=2) #, hatch=hatches[i % len(hatches)]\n",
    "    else:\n",
    "        plt.bar(years, percentage, width, bottom=bottom, label=topic, color=colors[i], edgecolor='white', linewidth=2) #, hatch=hatches[i % len(hatches)]\n",
    "    bottom += np.array(percentage)\n",
    "\n",
    "\n",
    "plt.xlim(start_year-1, end_year)\n",
    "\n",
    "# ylabel\n",
    "plt.title(f\"Disciplines Over Time: {analized_country}\", fontweight='bold', fontsize=15)\n",
    "plt.ylabel('Percentage of Works (%)', fontweight='bold', fontsize=13)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.35,1.), ncol=1)\n",
    "plt.savefig(cs_topics_over_time_plot_filename, bbox_inches='tight', dpi=plots_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4040fff",
   "metadata": {},
   "source": [
    "### CCDF (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc48255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ccdf(graph):\n",
    "    degree_sequence = sorted([d for _, d in graph.degree()], reverse=True)  # degree sequence\n",
    "    degreeCount = Counter(degree_sequence)\n",
    "    deg, cnt = zip(*degreeCount.items())\n",
    "    cs = np.cumsum(cnt)\n",
    "    return deg, cs\n",
    "\n",
    "years = range(start_year, end_year)\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Processing CCDF for year {year}...\")\n",
    "    output_path = os.path.join(ccdf_path, f\"ccdf_{year}.csv\")\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"CCDF for year {year} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    #load the network in a df\n",
    "    net_path = f\"../data/{year}.csv\"\n",
    "    net_df = pd.read_csv(net_path, names=['year', 'work_id', 'author_id1', 'author_id2'])\n",
    "\n",
    "    G = nx.from_pandas_edgelist(net_df, 'author_id1', 'author_id2')\n",
    "\n",
    "    deg, cs = eval_ccdf(G)\n",
    "    np.savetxt(output_path, np.array([deg, cs]).T, fmt='%d', delimiter=\",\", comments='', header='deg,cs')\n",
    "\n",
    "np.savetxt(os.path.join(output_path, 'ccdf_before.txt'), np.array([deg_before, cs_before]).T, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81afff2",
   "metadata": {},
   "source": [
    "### Plotting CCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba917cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"../plot_data/ccdfs\"\n",
    "\n",
    "# generate a figure with 5x5 subplots, each subplot is a ccdf for a year from 1990 to 2023\n",
    "fig, axs = plt.subplots(7, 5, figsize=(15, 15))\n",
    "axs = axs.flatten()\n",
    "\n",
    "first_idxs = {1990, 1995, 2000, 2005, 2010, 2015, 2020}\n",
    "last_raw_idxs = {2020, 2021, 2022, 2023}\n",
    "\n",
    "for i, year in enumerate(range(start_year, end_year)):\n",
    "    #print(f\"Plotting CCDF for year {year}...\")\n",
    "    ccdf_path = os.path.join(basepath, f\"ccdf_{year}.csv\")\n",
    "    deg, cs = np.loadtxt(ccdf_path, delimiter=',', skiprows=1, unpack=True)\n",
    "\n",
    "    axs[i].plot(deg, cs, marker='o', linestyle='None', color='darkturquoise', markersize=2)\n",
    "    axs[i].set_xscale('log')\n",
    "    axs[i].set_yscale('log')\n",
    "    axs[i].set_title(f'{year}', fontweight='bold', fontsize=13)\n",
    "\n",
    "    if year in last_raw_idxs:\n",
    "        axs[i].set_xlabel('Degree', fontweight='bold', fontsize=13)\n",
    "\n",
    "    if year in first_idxs:\n",
    "        axs[i].set_ylabel('CCDF', fontweight='bold', fontsize=13)\n",
    "    axs[i].grid(True)\n",
    "    axs[i].set_xlim(left=1)\n",
    "    axs[i].set_ylim(bottom=1)\n",
    "\n",
    "fig.delaxes(axs[34])\n",
    "plt.tight_layout()\n",
    "plt.savefig('./ccdfs_year_by_year.pdf', bbox_inches='tight', dpi=700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
