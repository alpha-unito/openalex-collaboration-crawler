#include <algorithm>
#include <args.hxx>
#include <atomic>
#include <chrono>
#include <cstdint>
#include <cstring>
#include <filesystem>
#include <fstream>
#include <functional>
#include <iostream>
#include <map>
#include <memory>
#include <mutex>
#include <optional>
#include <set>
#include <simdjson.h>
#include <sstream>
#include <string>
#include <string_view>
#include <thread>
#include <unordered_map>
#include <unordered_set>
#include <vector>

#include "ui.h"
#include "utils.h"

using namespace std::literals;

struct ArgsParsed {
    std::optional<std::string> format;
    std::optional<std::string> input;
    std::optional<std::string> output;
    std::optional<std::string> split;
    std::optional<std::string> extract_weighted;
};

static ArgsParsed parse_cli(int argc, const char **argv) {
    args::ArgumentParser parser("OpenAlex adjacency list generator (C++ port)");
    args::HelpFlag help(parser, "help", "Show help", {'h', "help"});

    args::ValueFlag<std::string> format(parser, "FORMAT",
                                        "Format of how to split years (comma separated list "
                                        "of ranges like 1990-2000).",
                                        {"format"});
    args::ValueFlag<std::string> input(parser, "INPUT", "Input JSONL file", {"input"});
    args::ValueFlag<std::string> output(parser, "OUTPUT", "Output base file name", {"output"});
    args::ValueFlag<std::string> extract_weighted(
        parser, "FILE",
        "Convert a generated adjacency list generated by this tool to a weighed representation",
        {"extract-weighted"});
    args::ValueFlag<std::string> split(parser, "FILE",
                                       "Split a dataset into single years datasets. This will "
                                       "remove the year field in the dataset.",
                                       {"split"});

    try {
        parser.ParseCLI(argc, argv);
    } catch (const args::Help &) {
        std::cout << parser;
        std::exit(0);
    } catch (const args::ParseError &e) {
        std::cerr << e.what() << "\n" << parser;
        std::exit(1);
    }

    ArgsParsed parameters;
    if (format) {
        parameters.format = args::get(format);
    }
    if (input) {
        parameters.input = args::get(input);
    }
    if (output) {
        parameters.output = args::get(output);
    }
    if (extract_weighted) {
        parameters.extract_weighted = args::get(extract_weighted);
    }
    if (split) {
        parameters.split = args::get(split);
    }
    return parameters;
}

struct UnorderedPair {
    std::string a;
    std::string b;
    UnorderedPair() = default;
    UnorderedPair(std::string x, std::string y) {
        if (x <= y) {
            a = std::move(x);
            b = std::move(y);
        } else {
            a = std::move(y);
            b = std::move(x);
        }
    }
    bool operator==(UnorderedPair const &o) const noexcept { return a == o.a && b == o.b; }
};

struct UnorderedPairHash {
    std::size_t operator()(UnorderedPair const &p) const noexcept {
        return std::hash<std::string>{}(p.a) ^ (std::hash<std::string>{}(p.b) << 1);
    }
};

static std::vector<std::string> extract_topics(simdjson::ondemand::array concepts) {
    std::vector<std::string> out;
    for (simdjson::ondemand::value v : concepts) {

        std::string_view sv;
        if (!v["display_name"].get(sv) && !sv.empty()) {
            out.emplace_back(sv);
            continue;
        }

        if (!v["id"].get(sv) && !sv.empty()) {
            if (constexpr std::string_view pref = "https://openalex.org/"; sv.rfind(pref) == 0) {
                sv.remove_prefix(pref.size());
            }
            out.emplace_back(sv);
        }
    }
    return out;
}

struct TimeInterval {
    uint64_t start, end;
    std::string file_name;

    bool isBetweenThisInterval(const int year) const { return start <= year && year < end; }
};

int handle_generate_weighted(const std::string &input_file_name) {
    info_colored("Generating weighted graph from CSV file: " + input_file_name);

    std::ifstream ifs(input_file_name);
    if (!ifs) {
        error_colored("Error: unable to open " + input_file_name);
        return 1;
    }

    uint64_t total_size = 0;
    try {
        total_size = std::filesystem::file_size(input_file_name);
    } catch (...) {
        total_size = 0;
    }
    auto bar = get_progress_bar("Loading & compressing CSV", total_size);
    std::unordered_map<UnorderedPair, uint64_t, UnorderedPairHash> weights;
    std::string line;
    while (std::getline(ifs, line)) {
        if (line.empty()) {
            continue;
        }
        bar.set_progress(bar.current() + line.size() + 1);

        std::vector<std::string> items = split_str(line, ',');
        if (items.size() <= 3) {
            continue;
        }
        std::string a = items[2];
        std::string b = items[3];
        // strip whitespace
        auto trim     = [](std::string &s) {
            size_t p1 = s.find_first_not_of(" \t\r\n");
            size_t p2 = s.find_last_not_of(" \t\r\n");
            if (p1 == std::string::npos) {
                s.clear();
                return;
            }
            s = s.substr(p1, p2 - p1 + 1);
        };
        trim(a);
        trim(b);
        UnorderedPair up(a, b);
        weights[up] += 1;
    }

    std::string output_file_name =
        "weighted_" + std::filesystem::path(input_file_name).filename().string();
    info_colored("Storing data to: " + output_file_name);
    std::ofstream ofs(output_file_name);
    if (!ofs) {
        warn_colored("Unable to create output file: " + output_file_name);
        return 1;
    }
    for (auto const &kv : weights) {
        ofs << kv.first.a << "," << kv.first.b << "," << kv.second << "\n";
    }
    info_colored("Done");
    return 0;
}

int main(int argc, const char **argv) {
    const std::string openalex_default_prefix = "https://openalex.org/";

    auto [format, input, output, split, extract_weighted] = parse_cli(argc, argv);

    const std::string input_file       = input.value_or("papers-filtered.jsonl");
    const std::string output_file_base = output.value_or("dataset.csv");

    if (extract_weighted) {
        return handle_generate_weighted(extract_weighted.value());
    }

    if (split) {
        return split_graph_to_single_years(split.value(), ".");
    }

    info_colored("Handling papers from " + input_file);

    std::vector<TimeInterval> intervals;
    std::vector<std::shared_ptr<std::mutex>> interval_file_mutexes;
    std::vector<std::shared_ptr<std::ofstream>> interval_files;

    if (format) {
        std::string fmt = *format;
        for (std::vector<std::string> ranges = split_str(fmt, ','); const auto &range : ranges) {
            std::vector<std::string> parts = split_str(range, '-');
            uint64_t start = 0, end = UINT64_MAX;
            if (!parts.empty()) {
                if (!parts[0].empty()) {
                    try {
                        start = std::stoull(parts[0]);
                    } catch (...) {
                        start = 0;
                    }
                }
                if (parts.size() > 1 && !parts[1].empty()) {
                    try {
                        end = std::stoull(parts[1]);
                    } catch (...) {
                        end = UINT64_MAX;
                    }
                }
            }

            std::string output_file_name = range + "_";
            std::ranges::replace(output_file_name, '-', '_');
            output_file_name += output_file_base;
            intervals.push_back({start, end, range});
            auto mtx = std::make_shared<std::mutex>();
            auto ofs =
                std::make_shared<std::ofstream>(output_file_name, std::ios::out | std::ios::trunc);
            if (!ofs->is_open()) {
                error_colored("Unable to open output file: " + output_file_name);
                return 1;
            }
            interval_file_mutexes.push_back(mtx);
            interval_files.push_back(ofs);
        }
    } else {
        std::string file_name = "all_dataset.csv";
        intervals.push_back({0, UINT64_MAX, file_name});
        auto mtx = std::make_shared<std::mutex>();
        auto ofs = std::make_shared<std::ofstream>(file_name, std::ios::out | std::ios::trunc);
        if (!ofs->is_open()) {
            error_colored("Unable to open output file: " + file_name);
            return 1;
        }
        interval_file_mutexes.push_back(mtx);
        interval_files.push_back(ofs);
    }

    info_colored("Will generate the following temporal adjacency lists:");
    for (size_t i = 0; i < intervals.size(); ++i) {
        const auto &[start, end, file_name] = intervals[i];
        std::string start_s                 = (start == 0 ? "START" : std::to_string(start));
        std::string end_s                   = (end == UINT64_MAX ? "END" : std::to_string(end));
        std::ostringstream ss;
        ss << "\t interval " << i << " -> from " << start_s << " to " << end_s << " -> ["
           << file_name << "]";
        info_colored(ss.str());
    }

    // get file size
    uint64_t file_size = 0;
    try {
        file_size = std::filesystem::file_size(input_file);
    } catch (...) {
        error_colored("Unable to open input file / unable to get input file size");
        return 1;
    }

    auto progress_bar = get_progress_bar("Processed", file_size);

    unsigned int num_threads = get_num_threads();

    uint64_t chunk_size = file_size / num_threads;

    std::vector<std::string> metadata_part_filenames;
    metadata_part_filenames.reserve(num_threads);

    std::vector<std::thread> workers;
    workers.reserve(num_threads);

    std::atomic<uint64_t> global_progress{0};

    for (unsigned int ID = 0; ID < num_threads; ++ID) {
        uint64_t start_offset = ID * chunk_size;
        uint64_t end_offset   = (ID == num_threads - 1) ? file_size : ((ID + 1) * chunk_size);

        std::string metadata_part = "metadata.part." + std::to_string(ID);
        metadata_part_filenames.push_back(metadata_part);

        workers.emplace_back([&, ID, start_offset, end_offset, metadata_part]() {
            std::ifstream ifs(input_file, std::ios::in | std::ios::binary);
            if (!ifs.is_open()) {
                error_colored("Thread " + std::to_string(ID) + ": unable to open input file");
                return;
            }
            // seek to first new line after start_offset
            seek_to_line_start(ifs, start_offset);

            std::ofstream meta_ofs(metadata_part, std::ios::out | std::ios::trunc);
            if (!meta_ofs.is_open()) {
                error_colored("Thread " + std::to_string(ID) +
                              ": unable to open metadata part file");
                return;
            }

            meta_ofs << "work_id,year,num_of_authors,topics\n";

            simdjson::ondemand::parser parser;

            std::string line;
            uint64_t bytes_read = 0;

            while (std::getline(ifs, line)) {
                if (line.empty()) {
                    continue;
                }

                bytes_read += line.size() + 1;
                if (ifs.tellg() == -1) {
                    error_colored("Error: unable to obtain current offset in input file");
                } else {
                    if (uint64_t absolute = start_offset + bytes_read;
                        ID != num_threads - 1 && absolute >= end_offset) {
                        ok_colored("Thread ID: " + std::to_string(ID) + " completed");
                        break;
                    }
                }

                uint64_t old = global_progress.fetch_add(line.size() + 1);
                progress_bar.set_progress(old + line.size() + 1);

                simdjson::padded_string padded(line.c_str(), line.size());
                simdjson::ondemand::document doc;
                try {
                    doc = parser.iterate(padded);
                } catch (const std::exception &e) {
                    continue;
                }

                std::string_view id_sv;
                try {
                    id_sv = doc["id"];
                } catch (...) {
                    continue;
                }
                std::string id_str(id_sv);
                if (id_str.rfind(openalex_default_prefix, 0) == 0) {
                    id_str = id_str.substr(openalex_default_prefix.size());
                }

                // Extract paper topics (i.e. OpenAlex concepts)
                simdjson::ondemand::array concepts_arr;
                if (doc["concepts"].get_array().error()) {
                    continue;
                }
                try {
                    concepts_arr = doc["concepts"].get_array();
                } catch (...) {
                    continue;
                }
                std::vector<std::string> topics = extract_topics(concepts_arr);
                std::string topic_list;
                if (!topics.empty()) {
                    std::ostringstream oss;
                    for (size_t i = 0; i < topics.size(); ++i) {
                        if (i) {
                            oss << ';';
                        }
                        oss << topics[i];
                    }
                    topic_list = oss.str();
                }
                uint64_t pub_year;
                try {
                    pub_year = doc["publication_year"].get_uint64();
                } catch (...) {
                    continue;
                }

                simdjson::ondemand::array authors_arr;
                try {
                    authors_arr = doc["authorships"].get_array();
                } catch (...) {
                    continue;
                }

                std::vector<std::string> author_vector;
                author_vector.reserve(8);
                for (simdjson::ondemand::value aentry : authors_arr) {
                    std::string_view aid_sv;
                    try {
                        aid_sv = aentry["author"]["id"].get_string();
                    } catch (...) {
                        continue;
                    }
                    std::string aid(aid_sv);
                    if (aid.rfind(openalex_default_prefix, 0) == 0) {
                        aid = aid.substr(openalex_default_prefix.size());
                    }
                    author_vector.push_back(std::move(aid));
                }

                if (author_vector.empty()) {
                    continue;
                }

                // Create edge and dump it to file.
                // NOTE: we do not store edges in memory as it is an expensive operation memory wise
                std::vector<std::string> edges;
                edges.reserve((author_vector.size() * (author_vector.size() - 1)) / 2 + 1);

                if (author_vector.size() == 1) {
                    edges.push_back(std::to_string(pub_year) + "," + id_str + "," +
                                    author_vector[0] + "," + author_vector[0]);
                } else {
                    for (size_t i = 0; i < author_vector.size(); ++i) {
                        for (size_t j = i + 1; j < author_vector.size(); ++j) {
                            edges.push_back(std::to_string(pub_year) + "," + id_str + "," +
                                            author_vector[i] + "," + author_vector[j]);
                        }
                    }
                }

                // Store metadatas
                meta_ofs << id_str << "," << std::to_string(pub_year) << ","
                         << std::to_string(author_vector.size()) << "," << topic_list << "\n";

                // write edges to appropriate interval file (first matching interval)
                for (size_t idx = 0; idx < intervals.size(); ++idx) {
                    if (const auto &ti = intervals[idx]; ti.isBetweenThisInterval(pub_year)) {
                        auto &mtx = *interval_file_mutexes[idx];
                        auto &ofs = *interval_files[idx];
                        std::lock_guard lock(mtx);
                        for (auto const &e : edges) {
                            ofs << e << "\n";
                        }
                        break;
                    }
                }
            }

            meta_ofs.flush();
        });
    }

    for (auto &t : workers) {
        t.join();
    }

    info_colored("Completed adjacency list generation");

    // merge metadata parts
    std::string metadata_filename = "metadata_" + output_file_base;
    info_colored("Storing adjacency list metadata to " + metadata_filename);
    merge_files(metadata_part_filenames, metadata_filename);
    info_colored("Done merging metadata files");

    return 0;
}
